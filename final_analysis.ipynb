{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhirpalshah/miniconda3/envs/condavenv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dhirpalshah/miniconda3/envs/condavenv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dhirpalshah/miniconda3/envs/condavenv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dhirpalshah/miniconda3/envs/condavenv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dhirpalshah/miniconda3/envs/condavenv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dhirpalshah/miniconda3/envs/condavenv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dhirpalshah/miniconda3/envs/condavenv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dhirpalshah/miniconda3/envs/condavenv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dhirpalshah/miniconda3/envs/condavenv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Cosine_Sim_1_2</th>\n",
       "      <th>Cosine_Sim_1_s</th>\n",
       "      <th>Cosine_Sim_2_s</th>\n",
       "      <th>Jaccard_Sim_1_2</th>\n",
       "      <th>Jaccard_Sim_1_s</th>\n",
       "      <th>Jaccard_Sim_2_s</th>\n",
       "      <th>BLEU_Sim_1_2</th>\n",
       "      <th>BLEU_Sim_1_s</th>\n",
       "      <th>BLEU_Sim_2_s</th>\n",
       "      <th>ROUGE_L_Sim_1_2</th>\n",
       "      <th>ROUGE_L_Sim_1_s</th>\n",
       "      <th>ROUGE_L_Sim_2_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1i7s0u</td>\n",
       "      <td>0.632732</td>\n",
       "      <td>0.167837</td>\n",
       "      <td>0.176242</td>\n",
       "      <td>0.233983</td>\n",
       "      <td>0.086379</td>\n",
       "      <td>0.116719</td>\n",
       "      <td>6.797190e-232</td>\n",
       "      <td>8.368341e-232</td>\n",
       "      <td>8.368341e-232</td>\n",
       "      <td>0.214976</td>\n",
       "      <td>0.088028</td>\n",
       "      <td>0.094737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1i7qst</td>\n",
       "      <td>0.689079</td>\n",
       "      <td>0.258419</td>\n",
       "      <td>0.439947</td>\n",
       "      <td>0.260652</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.135048</td>\n",
       "      <td>6.420645e-232</td>\n",
       "      <td>8.859356e-232</td>\n",
       "      <td>8.859356e-232</td>\n",
       "      <td>0.272637</td>\n",
       "      <td>0.096718</td>\n",
       "      <td>0.092025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1i7hzo</td>\n",
       "      <td>0.481272</td>\n",
       "      <td>0.301546</td>\n",
       "      <td>0.243571</td>\n",
       "      <td>0.210784</td>\n",
       "      <td>0.081911</td>\n",
       "      <td>0.104730</td>\n",
       "      <td>6.561680e-232</td>\n",
       "      <td>9.405151e-232</td>\n",
       "      <td>9.342655e-232</td>\n",
       "      <td>0.143713</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.077348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1iawxh</td>\n",
       "      <td>0.368036</td>\n",
       "      <td>0.181209</td>\n",
       "      <td>0.223521</td>\n",
       "      <td>0.114441</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.103321</td>\n",
       "      <td>6.848004e-232</td>\n",
       "      <td>8.256980e-232</td>\n",
       "      <td>8.456086e-232</td>\n",
       "      <td>0.129801</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.117137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1i9v7i</td>\n",
       "      <td>0.387593</td>\n",
       "      <td>0.203380</td>\n",
       "      <td>0.231738</td>\n",
       "      <td>0.177945</td>\n",
       "      <td>0.093093</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>6.950441e-232</td>\n",
       "      <td>8.532517e-232</td>\n",
       "      <td>8.414799e-232</td>\n",
       "      <td>0.141317</td>\n",
       "      <td>0.080257</td>\n",
       "      <td>0.113924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Cosine_Sim_1_2  Cosine_Sim_1_s  Cosine_Sim_2_s  Jaccard_Sim_1_2  \\\n",
       "0  1i7s0u        0.632732        0.167837        0.176242         0.233983   \n",
       "1  1i7qst        0.689079        0.258419        0.439947         0.260652   \n",
       "2  1i7hzo        0.481272        0.301546        0.243571         0.210784   \n",
       "3  1iawxh        0.368036        0.181209        0.223521         0.114441   \n",
       "4  1i9v7i        0.387593        0.203380        0.231738         0.177945   \n",
       "\n",
       "   Jaccard_Sim_1_s  Jaccard_Sim_2_s   BLEU_Sim_1_2   BLEU_Sim_1_s  \\\n",
       "0         0.086379         0.116719  6.797190e-232  8.368341e-232   \n",
       "1         0.115942         0.135048  6.420645e-232  8.859356e-232   \n",
       "2         0.081911         0.104730  6.561680e-232  9.405151e-232   \n",
       "3         0.078067         0.103321  6.848004e-232  8.256980e-232   \n",
       "4         0.093093         0.147059  6.950441e-232  8.532517e-232   \n",
       "\n",
       "    BLEU_Sim_2_s  ROUGE_L_Sim_1_2  ROUGE_L_Sim_1_s  ROUGE_L_Sim_2_s  \n",
       "0  8.368341e-232         0.214976         0.088028         0.094737  \n",
       "1  8.859356e-232         0.272637         0.096718         0.092025  \n",
       "2  9.342655e-232         0.143713         0.067797         0.077348  \n",
       "3  8.456086e-232         0.129801         0.074074         0.117137  \n",
       "4  8.414799e-232         0.141317         0.080257         0.113924  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'final_generated_responses_corrected.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define Jaccard similarity function\n",
    "def jaccard_similarity(doc1, doc2):\n",
    "    words_doc1 = set(doc1.split()) \n",
    "    words_doc2 = set(doc2.split())\n",
    "    intersection = words_doc1.intersection(words_doc2)\n",
    "    union = words_doc1.union(words_doc2)\n",
    "    return float(len(intersection)) / len(union)\n",
    "\n",
    "# Define custom ROUGE-L function\n",
    "def calculate_rouge_l(reference, candidate):\n",
    "    reference_tokens = reference.split()\n",
    "    candidate_tokens = candidate.split()\n",
    "    reference_len = len(reference_tokens)\n",
    "    candidate_len = len(candidate_tokens)\n",
    "    \n",
    "    dp = [[0] * (candidate_len + 1) for _ in range(reference_len + 1)]\n",
    "    \n",
    "    for i in range(reference_len + 1):\n",
    "        for j in range(candidate_len + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                dp[i][j] = 0\n",
    "            elif reference_tokens[i-1] == candidate_tokens[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
    "                \n",
    "    lcs_len = dp[reference_len][candidate_len]\n",
    "    precision = lcs_len / candidate_len if candidate_len > 0 else 0\n",
    "    recall = lcs_len / reference_len if reference_len > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return f1_score\n",
    "\n",
    "# Vectorize text for cosine similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[['generated_response_prompt1', 'generated_response_prompt2', 'physician_comments']].values.flatten())\n",
    "\n",
    "# Calculate cosine similarities\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "similarity_results = pd.DataFrame(data['id'], columns=['id'])\n",
    "\n",
    "# Calculating all similarities\n",
    "similarity_functions = [cosine_similarity, jaccard_similarity, sentence_bleu, calculate_rouge_l]\n",
    "labels = ['Cosine', 'Jaccard', 'BLEU', 'ROUGE_L']\n",
    "\n",
    "# Calculate all pairwise comparisons\n",
    "for func, label in zip(similarity_functions, labels):\n",
    "    # Define the pairs for comparison\n",
    "    pairs = [('generated_response_prompt1', 'generated_response_prompt2'),\n",
    "             ('generated_response_prompt1', 'physician_comments'),\n",
    "             ('generated_response_prompt2', 'physician_comments')]\n",
    "    \n",
    "    for pair in pairs:\n",
    "        col_name = f'{label}_Sim_{pair[0][-1]}_{pair[1][-1]}'  # Correct column name creation based on prompts and comments\n",
    "        if func == cosine_similarity:\n",
    "            similarity_results[col_name] = [\n",
    "                func(tfidf_vectorizer.transform([row[pair[0]]]), \n",
    "                     tfidf_vectorizer.transform([row[pair[1]]]))[0, 0]\n",
    "                for index, row in data.iterrows()\n",
    "            ]\n",
    "        else:\n",
    "            similarity_results[col_name] = [\n",
    "                func(row[pair[0]], row[pair[1]])\n",
    "                for index, row in data.iterrows()\n",
    "            ]\n",
    "\n",
    "similarity_results.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
